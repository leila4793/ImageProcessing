{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4082ad75-d882-456d-b6a9-9f2ec93eab90",
   "metadata": {},
   "source": [
    "__contents:__\n",
    "\n",
    "1. [Geometric transformations](#Geometric_transformations)\n",
    "   * 1.1.[Image translation](#Image_translation)\n",
    "   * 1.2.[Rotation](#Rotation)\n",
    "   * 1.3.[Scaling](#Scaling)\n",
    "   * 1.4.[Flipping](#Flipping)\n",
    "   * 1.5.[Shearing](#Shearing)\n",
    "   * 1.6.[Cropping](#Cropping)\n",
    "2. [Arithmetic Operations](#Arithmetic_Operations)\n",
    "   * 2.1.[Addition](#Addition)\n",
    "     - 2.1.1.[weighted addition](#weighted_addition)\n",
    "   * 2.2.[Subtraction](#Subtraction)\n",
    "   * 2.3.[Multiplication and division](#Multi_division)\n",
    "   * 2.4.[Bitwise operations](#Bitwise_operations)\n",
    "     - 2.4.1.[AND](#AND)\n",
    "     - 2.4.2.[OR](#OR)\n",
    "     - 2.4.3.[XOR](#XOR)\n",
    "     - 2.4.4.[NOT](#NOT)\n",
    "   * 2.5.[Channels and color spaces](#ChannelsColorCpaces)\n",
    "     - 2.5.1.[Red Green Blue (RGB) color space](#RGB)\n",
    "     - 2.5.2.[Blue Green Red (BGR) color space](#BGR)\n",
    "     - 2.5.3.[Hue Saturation Value (HSV) color space](#HSV)\n",
    "     - 2.5.4.[Hue Saturation Lightness (HSL) color space](#HSL)\n",
    "     - 2.5.5.[LAB color space](#LAB)\n",
    "     - 2.5.6.[YCbCr color space](#YCbCr)\n",
    "     - 2.5.7.[Grayscale](#Grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f78b48-6abf-42cb-becf-eeb7f7b0da58",
   "metadata": {},
   "source": [
    "# <h2 style=\"color: blue;\"> 1.Geometric transformations <a id='Geometric_transformations'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed7831-bd36-40b4-8215-f9207c24843b",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "In technical terms, image processing involves transforming the coordinates of image points from one coordinate system to another. Using various transformation functions, it is possible to map pixel coordinates in the original image to new coordinates in the transformed image, resulting in different types of transformations.\n",
    "\n",
    "As we move forward with this chapter, we will explore various image transformation techniques, including rotation, scaling, and more, beginning with image translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1121b-8269-4338-8279-fd47ac9e9d71",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.1.Image translation <a id='Image_translation'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9beeac-ec56-4abe-9a4b-67d5e8303800",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image translation is the process of shifting an image in horizontal and vertical directions. Using image translation we can move our image on the x and y axis by a specified amount.\n",
    "\n",
    "To perform image translation, a translation matrix is applied to the image that maps the original coordinates to the new, shifted coordinates. Image translations can be performed by applying affine transformations to an input image.\n",
    "We use the ```cv2.warpAffine``` function in OpenCV to apply affine transformations:\n",
    "```python\n",
    "cv2.warpAffine(src, M, dsize, dst, flags=INTER_LINEAR,borderMode=BORDER_CONSTANT, borderValue=0)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src:``` The source image on which transformations will be applied.\n",
    "* ```M:``` The transformation matrix.\n",
    "* ```dsize:``` Size of the output image.\n",
    "* ```dst:``` dst is an optional output image that stores the result of transformation. The dst image must be of the same size and type as the input image src. If the dst image is not provided, the OpenCV function will create an output image of the same size and type as the input image and return it as the output.\n",
    "* ```Flags:``` It is an optional parameter that specifies the interpolation method to be used.\n",
    "* ```borderMode:``` This specifies how to handle the pixels that fall outside the image boundaries. It is a with default value as ```cv2.BORDER_CONSTANT```.\n",
    "* ```borderValue:``` This is used only with ```cv2.BORDER_CONSTANT``` mode and specifies the constant value used to pad the image. It is an with default value as 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48d431d-09b8-4c85-9008-7c5090d80eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('imgs/fruits.png')\n",
    "# Define the translation matrix\n",
    "tx = 50 # x-direction\n",
    "ty = 100 # y-direction\n",
    "M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "# Apply the translation to the image\n",
    "rows, cols, _ = img.shape\n",
    "translated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Translated Image', translated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea6f44-79c8-4ba6-8a26-b95cdca4d074",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.2. Rotation <a id='Rotation'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fa803-bb8a-4ba4-b783-bc73d2886d1b",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image rotation is the process of rotating an image by an angle around its center point.There are two ways to perform image rotation:\n",
    "\n",
    "1. ```cv2.rotate```function for image rotation. this function is that it can __only__ rotate the image by ```90 degrees in a clockwise or anticlockwise direction```. It does __not__ allow us to choose an arbitrary angle to rotate the image.\n",
    "```python\n",
    "cv2.rotate(src, rotateCode, dst)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src:``` The source image on which transformations will be applied.\n",
    "* ```rotateCode:``` This parameter specifies the direction and angle in which the image should be rotated. The possible values for rotateCode are:\n",
    "- ```cv2.ROTATE_90_CLOCKWISE:``` Rotates the image 90 degrees in clockwise direction.\n",
    "- ```cv2.ROTATE_90_COUNTERCLOCKWISE:``` Rotates the image 90 degrees in counter clockwise direction.\n",
    "- ```cv2.ROTATE_180:``` Rotates the image by 180 degrees.\n",
    "* ```dst:``` dst is an optional output image that stores the result of transformation.\n",
    "\n",
    "2. using the ```cv2.warpAffine``` function: We use another function, ```cv2.getRotationMatrix2D```, to generate the rotation matrix used with the cv2.warpAffine function.\n",
    "```python\n",
    "cv2.getRotationMatrix2D(center = None, angle, scale = 1)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```center:``` The center point(x,y) of the image rotation. The default value for is None. If a point is not specified, the function will use the center point of the image.\n",
    "* ```angle:``` The angle of rotation in degrees. Positive values indicate counter-clockwise direction, while negative values correspond to clockwise rotation.\n",
    "* ```scale:``` The scale parameters is used to scale the size of the image by a factor. The default value for in 1, which means the output image is the same as the size of the input image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2fb2d6-d889-499a-9d12-a1517be1ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_img_90cw = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE) # Rotate clockwise by 90 degrees\n",
    "rot_img_90ccw = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) # Rotate counterclockwise by 90 degrees\n",
    "rot_img_180 = cv2.rotate(img, cv2.ROTATE_180) # Rotate by 180 degrees\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Rotated 90 CW', rot_img_90cw)\n",
    "cv2.imshow('Rotated 90 CCW', rot_img_90ccw)\n",
    "cv2.imshow('Rotated 180', rot_img_180)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83467266-8a7d-4244-94f1-df10809f0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = img.shape[:2]\n",
    "# Get rotation matrices.\n",
    "M1 = cv2.getRotationMatrix2D((100,100), 30, 1)\n",
    "M2 = cv2.getRotationMatrix2D((cols/2,rows/2), 45, 2)\n",
    "M3 = cv2.getRotationMatrix2D((cols/2,rows/2), -90, 1)\n",
    "# Perform rotation\n",
    "rotated1 = cv2.warpAffine(img, M1, (cols, rows))\n",
    "rotated2 = cv2.warpAffine(img, M2, (cols, rows))\n",
    "rotated3 = cv2.warpAffine(img, M3, (cols, rows))\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Rotated Image 1', rotated1)\n",
    "cv2.imshow('Rotated Image 2', rotated2)\n",
    "cv2.imshow('Rotated Image 3', rotated3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a822ecf-0d07-474d-8959-c6267c0f9bf8",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "We have used the scaling factor of 2 for our image. Earlier, we discussed the importance of specifying the output image size in the warpAffine function. In this instance, we set the output picture size to match the size of the input image. To obtain our scaled image, we must replace these numbers with new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60cfe2-28cb-41f5-b6d1-4b7784f2673e",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.3.Scaling <a id='Scaling'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5fe12e-aeea-484b-9de6-440700df86fb",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image scaling is a common task in image processing that allows us to resize images according to our requirements. When resizing an image, it is important to maintain the aspect ratio of the image to avoid producing a distorted image.\n",
    "\n",
    "We use the ```cv2.resize()``` function to resize images using OpenCV:\n",
    "```python\n",
    "cv2.resize(src, dst, dsize, fx = 0, fy = 0, interpolation = cv2.INTER_LINEAR)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src:``` The source image on which transformations will be applied.\n",
    "* ```dst:``` dst is an optional output image that stores the result of transformation. \n",
    "* ```dsize:``` The size of the output image after resizing.\n",
    "* ```fx:``` The scaling factor along the horizontal axis.\n",
    "* ```fy:``` The scaling factor along the vertical axis.\n",
    "If dsize __is not specified__, it will automatically be calculated using the scaling factors fx and fy.\n",
    "```python\n",
    "dsize = (int(src.shape[1] * fx), int(src.shape[0] * fy)).\n",
    "```\n",
    "* ```interpolation:``` Interpolation refers to the technique used to estimate the new pixel values after applying geometric transformations. Following values can be used for this parameter:\n",
    "  - ```cv2.INTER_NEAREST:``` nearest neighbor interpolation.\n",
    "  - ```cv2.INTER_LINEAR:``` bilinear interpolation.\n",
    "  - ```cv2.INTER_CUBIC:``` bicubic interpolation over 4×4 pixel neighborhood.\n",
    "  - ```cv2.INTER_AREA:``` resampling using pixel area relation. It is the recommended interpolation method when shrinking an image.\n",
    "  - ```cv2.INTER_LANCZOS4:``` Lanczos interpolation over 8x8 pixel neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13130af-3673-409c-898f-caba6bf5269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = cv2.resize(img, (0,0), fx = 0.5, fy = 0.5) # Resize the image to half its size\n",
    "resized_img = cv2.resize(img, (640, 480)) # Resize the image to a specific width and height\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Resized Image', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bb5e0-54c8-46b0-866b-e951c0368303",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image scaling can also be implemented using the ```cv2.warpAffine``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8eba97-1679-4a57-9159-0beb9dda127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = (400, 400) # Define the new size\n",
    "# Compute the scaling factors for x and y axis\n",
    "sx = new_size[0]/img.shape[1]\n",
    "sy = new_size[1]/img.shape[0]\n",
    "M = np.float32([[sx, 0, 0], [0, sy, 0]]) # Define the transformation matrix\n",
    "resized_img = cv2.warpAffine(img, M, new_size) # Apply the affine transformation\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Resized Image', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c1fe9-6b66-4e4b-83d0-4ab5adb364de",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.4.Flipping <a id='Flipping'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3085d-a2a2-4fde-ad00-ef4943c6b604",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image flipping is used to flip an image horizontally or vertically. We can use the ```cv2.flip``` function to implement image flipping:\n",
    "```python\n",
    "cv2.flip(src, dst, flipCode = 1)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be flipped\n",
    "* ```dst:``` Output Variable\n",
    "* ```flipCode:``` A flag that specifies how to flip the array. The following values can be used with this parameter.\n",
    "  - ```'0':``` Vertical flip. Image is flipped around the x-axis.\n",
    "  - ```'1':``` Horizontal flip. Image is flipped around the y-axis\n",
    "  - ```'-1':``` Image is flipped around both axes\n",
    "The default value for is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2941fc5-77c4-49e0-88b0-df542e822271",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flip = cv2.flip(img, 1) # Flip the image horizontally\n",
    "y_flip = cv2.flip(img, 0)# Flip the image vertically\n",
    "xy_flip = cv2.flip(img, -1)# Flip the image on both axes\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Horizontal flip', x_flip)\n",
    "cv2.imshow('Vertical flip', y_flip)\n",
    "cv2.imshow('Both axes', xy_flip)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8164b-f52f-460c-b0c3-f92a92841f61",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.5.Shearing <a id='Shearing'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2554e9-73ea-4d25-9e27-0bf5505c92ab",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "Image Shearing is a linear transformation that distorts an image along one of its axes. When an image is sheared along the x-axis, the pixels in the image are shifted horizontally. \n",
    "We will use the ```cv2.warpAffine``` function to implement image shearing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8dd951e-f1b3-489d-bc2f-aae01ebbd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shearing parameters\n",
    "shear_factor_x = 0.2\n",
    "shear_factor_y = 0.3\n",
    "# Obtain shearing matrices\n",
    "M_x = np.array([[1, shear_factor_x, 0], [0, 1, 0]])\n",
    "M_y = np.array([[1, 0, 0], [shear_factor_y, 1, 0]])\n",
    "# Apply shearing transformations\n",
    "rows, cols = img.shape[:2]\n",
    "sheared_img_x = cv2.warpAffine(img, M_x, (cols + int(rows * shear_factor_x), rows))\n",
    "sheared_img_xy = cv2.warpAffine(sheared_img_x, M_y, (cols + int(rows * shear_factor_x), rows + int(cols * shear_factor_y)))\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Sheared Image (X axis)', sheared_img_x)\n",
    "cv2.imshow('Sheared Image (X and Y axis)', sheared_img_xy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ac5d38-a16c-4ed1-8370-b16243b2d3e2",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.6.Cropping <a id='Cropping'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5f577-1503-4273-a441-d9e15c31cce5",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "Image cropping is the process of selecting a rectangular portion of an image. Cropping can be considered a type of geometric transformation, where a section of the source image is removed to produce a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a67f93-bdf8-4de2-ac78-727cc26952a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ROI coordinates\n",
    "x1, y1 = 100, 100 # top-left corner\n",
    "x2, y2 = 300, 400 # bottom-right corner\n",
    "\n",
    "# Crop image\n",
    "cropped_img = img[y1:y2, x1:x2]\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Cropped Image', cropped_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8d540-024c-4d6a-b589-43685cdfcff2",
   "metadata": {},
   "source": [
    "# <h2 style=\"color: blue;\"> 2.Arithmetic Operations <a id='Arithmetic_Operations'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eca904-b1e3-4d28-ac61-85ff4db31716",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "Arithmetic operations are a fundamental concept in image processing. These operations involve performing basic mathematical operations on images to generate new images with different properties. These operations are performed on the pixel values and allow us to extract useful information from the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2301882-9798-46ee-bb4e-70eb8979cd0a",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.1.Addition <a id='Addition'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481e4b4-4f25-4cfb-a530-1dac5c35fc2d",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image addition is a basic arithmetic operation that involves adding pixel values of two or more images to produce a single image.\n",
    "We use the ```cv2.add()``` function to perform addition using the OpenCV library:\n",
    "```python\n",
    "cv2.add(src1, src2, dst, mask, dtype)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src1 and src2:``` The source images to be added. Both images should be of the same type and size.\n",
    "* ```dst:``` Output Variable.\n",
    "* ```mask:``` Masking allows us to choose specific pixels where the operation has to be performed. This is an . If it is left blank, the operation is performed on all the pixels.\n",
    "* ```dtype:``` The data type of the output. This is an optional parameter that defaults to the input data type if left blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb09d1d-6c3f-47a1-961b-8f1b635aec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2.add() result:\n",
      " [[110 220 180]\n",
      " [ 90 255 160]\n",
      " [220 255 140]]\n",
      "Numpy addition result:\n",
      " [[110 220 180]\n",
      " [ 90  44 160]\n",
      " [220  24 140]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Initialize two sample 3x3 images\n",
    "img1 = np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]], dtype = np.uint8)\n",
    "img2 = np.array([[100, 200, 150], [50, 250, 100], [150, 200, 50]], dtype = np.uint8)\n",
    "# Add the images\n",
    "cv2_add = cv2.add(img1, img2)\n",
    "print('cv2.add() result:\\n', cv2_add)\n",
    "# Add the images using numpy addition\n",
    "numpy_add = img1 + img2\n",
    "print('Numpy addition result:\\n', numpy_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6961fc-5b79-47ac-a982-8b086b0e05ff",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.1.1.weighted addition <a id='weighted_addition'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71ad8d-2a83-42f0-b04c-ce5d70a40ce9",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "the weighted addition of images, which means that each image has a different contribution to the final output, and these contributions are not equal, as shared earlier.\n",
    "\n",
    "We use the ```cv2.addWeighted()``` function for this:\n",
    "```python\n",
    "cv2.addWeighted(src1, alpha = 1.0, src2, beta = 0.0, gamma = 0.0, dst, dtype)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src1 and src2:``` The source images to be added. Both images should be of the same type and size.\n",
    "* ```alpha:``` Weight of the first image. The range of alpha is 0 to 1, where 0 means the first image will not contribute to the output, and 1 means that the first image will have the maximum contribution to the output. The default value for alpha is 1.\n",
    "* ```beta:``` Weight of the second image. The range of beta is between 0 and 1, similar to the alpha parameters. The default value for beta is 0.\n",
    "* ```gamma:``` A scalar value that can be added to all the pixels after the weighted sum is calculated. This is an with default value as 0.\n",
    "* ```dst:``` Output array.\n",
    "* ```dtype:``` The data type of the output. This is an optional parameter that defaults to the input data type if left blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0bfe5f-42b4-429a-8363-7b468e5de835",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('imgs/fruits.png')\n",
    "img2 = cv2.imread('imgs/fruits.png')\n",
    "# Add the two images with different weights\n",
    "result = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)\n",
    "cv2.imshow('Result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f30b4c-ba13-4336-80bd-9f532770fc61",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.2.Subtraction <a id='Subtraction'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc8c9d-8ffa-4697-808a-41d12b5c811e",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    " \n",
    "We use the ```cv2.subtract()``` function for image subtraction in OpenCV. This function takes two images as inputs and subtracts the pixel values of the second image from the first image. Any negative values resulting from the subtraction are set to 0, as discussed earlier:\n",
    "```python\n",
    "cv2.subtract(src1, src2, dst, mask, dtype)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src1 and src2:``` The source images to be subtracted. __Both images should be of the same type and size.__ The src2 image is subtracted from src1 image.\n",
    "* ```dst:``` Output variable.\n",
    "* ```mask:``` Masking allows us to choose specific pixels where the operation has to be performed. This is an. If it is left blank, the operation is performed on all the pixels.\n",
    "* ```dtype:``` The data type of the output. This is an optional parameter that defaults to the input data type if left blank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfaa88-ad05-42cb-9ce7-c1147411b513",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.3.Multiplication and division <a id='Multi_division'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf5917-3f29-481e-8439-5dd096d91c3b",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Multiplication and division of images involves multiplying/dividing each pixel value of one image with the corresponding pixel value of another image. \n",
    "__docimentation:__\n",
    "```python\n",
    "cv2.multiply(src1, src2, dst, scale = 1.0, dtype)\n",
    "cv2.divide(src1, src2, dst, scale = 1.0, dtype)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src1 and src2:``` The source images to be multiplied or divided.\n",
    "* ```dst:``` Output variable.\n",
    "* ```scale:``` The scale factor in __cv2.multiply()__ is a scalar value that is multiplied with the product of the corresponding pixel values of the input images. The scale parameter in __cv2.divide__ is used to divide the numerator (source image) by a scalar value. It is an optional parameter and its default value is 1.0.\n",
    "* ```dtype:``` The data type of the output. This is an optional parameter that defaults to the input data type if left bank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f9b6b-cb3c-4c8e-8f8d-8455ec631457",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.4.Bitwise operations <a id='Bitwise_operations'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7453f-e932-41dc-bcc7-d3e0e3caeb87",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "Bitwise operations can be used to combine two images or to extract and modify specific parts of these images. Bitwise operations, on the other hand, involve manipulating the individual bits of the pixel values in an image. These operations are based on the logical operations of AND, OR, XOR, and NOT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52d16c-af48-4a28-9ad2-a6d1aa63c040",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.4.1.AND <a id='AND'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fb925-5cb0-418b-b552-341c650831f9",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Bitwise AND Is a binary operation that takes two images and performs the logical AND operation on them. This operation results in an image where the resultant pixel is 1 only if the corresponding pixel on both images is 1. If any of the bits in the input image is 0, the resulting pixel value is 0.\n",
    "The syntax for this operation is:\n",
    "```python\n",
    "cv2.bitwise_and(src1, src2, dst, mask)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb84ec-70e9-40d3-82c7-95e71998ef59",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.4.2.OR <a id='OR'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bc718-4bab-4d46-9959-51614a29c288",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Bitwise OR is a binary operation that takes two images and performs the logical OR operation on them. This operation results in an image where the resultant pixel is 1 if either of the corresponding pixels on both images is 1. If both of the bits on the input images are 0, the resulting pixel value is 0.The syntax for this operation is:\n",
    "```python\n",
    "cv2.bitwise_or(src1, src2, dst, mask)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edf6b4-46bb-473b-b804-1523c2ea978f",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.4.3.XOR <a id='XOR'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02697e0-e7ad-4189-bcd8-2fd4913b621b",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Bitwise XOR is a binary operation that takes two images and performs the logical XOR (exclusive OR) operation on them. This operation results in an image where the resultant pixel is 1 if only one of the corresponding pixels on the input images is 1. If both of the bits on the input images are 0 or 1, the resulting pixel value is 0.\n",
    "The syntax for this operation is:\n",
    "```python\n",
    "cv2.bitwise_xor(src1, src2, dst, mask)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150b351-5cd7-4b07-865c-481e834a8dd0",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.4.4.NOT <a id='NOT'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbad47d-18cb-44e0-b6f1-0b039f8b9fbe",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "Bitwise NOT is a unary operation that takes a single image and performs the logical NOT operation on it. This operation results in an image where all the values of the images are reversed. All pixel values corresponding to 0 are set to 1, and all pixel values corresponding to 1 are set to 0 during the bitwise NOT operation.The syntax for this operation is:\n",
    "```python\n",
    "cv2.bitwise_not(src, dst, mask)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133fa31-e243-44f7-a74a-b1993f0dff54",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "the parameters of all bitwise operations is:\n",
    "__Parameters:__\n",
    "* ```src1 and src:``` The source images to be used for bitwise operations.\n",
    "* ```dst:``` Output variable.\n",
    "* ```mask:``` This is optional mask used to specify which pixels of the input images should be processed. The default value is None, meaning the full image will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c45f6f0-6500-498d-b37c-591d7c85ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two black and white images\n",
    "img1 = np.zeros((400, 400), dtype=np.uint8)\n",
    "img2 = np.zeros((400, 400), dtype=np.uint8)\n",
    "# Draw a rectangle on img1\n",
    "cv2.rectangle(img1, (50, 50), (350, 350), (255, 255, 255), -1)\n",
    "# Draw a circle on img2\n",
    "cv2.circle(img2, (200, 200), 150, (255, 255, 255), -1)\n",
    "# Perform bitwise AND\n",
    "bitwise_and = cv2.bitwise_and(img1, img2)\n",
    "# Perform bitwise OR\n",
    "bitwise_or = cv2.bitwise_or(img1, img2)\n",
    "# Perform bitwise XOR\n",
    "bitwise_xor = cv2.bitwise_xor(img1, img2)\n",
    "# Perform bitwise NOT on img1\n",
    "bitwise_not = cv2.bitwise_not(img1)\n",
    "cv2.imshow('img1', img1)\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.imshow('AND', bitwise_and)\n",
    "cv2.imshow('OR', bitwise_or)\n",
    "cv2.imshow('XOR', bitwise_xor)\n",
    "cv2.imshow('NOT of img1', bitwise_not)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c00f0-accf-4023-86f3-a80eaacc9eb3",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.5.Channels and color spaces <a id='ChannelsColorCpaces'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12f800-0bd6-418d-950e-19083e2ed36e",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "In OpenCV, images are represented as a matrix of pixel values. The number of channels in an image is the number of matrices used to represent the image.\n",
    "1. A ```grayscale``` image has one channel\n",
    "\n",
    "2. A ```color image``` typically has three channels ```(red, green, and blue)```.\n",
    "We will discuss the most commonly used color spaces in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da32489-5fc4-493a-8299-8dd9e9e07eec",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.5.1.Red Green Blue (RGB) color space <a id='RGB'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2432d-0042-4a10-ad27-67a05458314b",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "RGB color space contains red, blue and green channels to represent an image. Each channel in the RGB color space has values ranging from 0 to 255, which describe the intensity of a particular color. A value of 0 represents no color or complete darkness, while a value of 255 represents the maximum intensity or full brightness of that color. here is some examples:\n",
    "| Color      | RGB Code       | R   | G   | B   |\n",
    "|------------|----------------|-----|-----|-----|\n",
    "| Red        | (255,0,0)      | 255 | 0   | 0   |\n",
    "| Green      | (0,255,0)      | 0   | 255 | 0   |\n",
    "| Blue       | (0,0,255)      | 0   | 0   | 255 |\n",
    "| Orange     | (255,165,0)    | 255 | 165 | 0   |\n",
    "| Brown      | (165,42,42)    | 165 | 42  | 42  |\n",
    "| Light Gray | (211,211,211)  | 211 | 211 | 211 |\n",
    "| Dark Gray  | (64,64,64)     | 64  | 64  | 64  |\n",
    "\n",
    "Let us try to visualize these channels of an image with the help of some code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8cd1d45-c5e8-4772-aa8d-1989fe93232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('imgs/fruits.png')\n",
    "im1=img.copy()\n",
    "im2=img.copy()\n",
    "im3=img.copy()\n",
    "im1[:,:,0]=0\n",
    "im1[:,:,1]=0\n",
    "im2[:,:,2]=0\n",
    "im2[:,:,1]=0\n",
    "im3[:,:,2]=0\n",
    "im3[:,:,0]=0\n",
    "cv2.imshow('Original Image' , img)\n",
    "cv2.imshow('Red channel' , im1)\n",
    "cv2.imshow('Blue channel' , im2)\n",
    "cv2.imshow('Green channel' , im3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01dd39f-c1b9-4d86-a382-662453777ffa",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.5.2.Blue Green Red (BGR) color space <a id='BGR'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3679394-eb13-42eb-ad64-edc81047b642",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "BGR color space is the RGB color space reversed. This is the most commonly used color space in OpenCV. There is no other difference with respect to RGB color space except for the positioning of channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094e65b-240c-46bc-9aa2-7695bc12108c",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.5.3.Hue Saturation Value (HSV) color space <a id='HSV'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70372d1b-1e0c-4248-87ff-23ededcf1062",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Hue Saturation and Value are the three components of this color space.\n",
    "* ```Hue:``` Hue refers to the pure color that we perceive.The Hue value ranges from ```0 to 360``` degrees, representing a full circle of colors. __Red is located at 0 degrees, green at 120 degrees, and blue at 240 degrees__.\n",
    "* ```Saturation:``` Saturation represents the intensity of the color. The saturation value is represented as a percentage from $0%$ to $100%$.\n",
    "* ```Value:``` Value is the amount of white or black added to the hue. It represents the lightness or the darkness of the color. This is also represented as a percentage, ranging from $0%$ to $100%$.\n",
    "We will use the cv2.cvtColor function to change the color spaces of an image.\n",
    "```python\n",
    "cv2.cvtColor(src, code, dst, dstCn=0)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be converted.\n",
    "* ```code:``` This represents the type of conversion you want to perform. This parameter defines the current color space of the image and specifies the desired color space to which the image needs to be converted.\n",
    "  - ```cv2.COLOR_BGR2HSV:``` Converts an image from __BGR__ to __HSV__.\n",
    "  - ```cv2.COLOR_BGR2GRAY:``` Converts an image from __BGR__ to __grayscale__.\n",
    "  - ```cv2.COLOR_HSV2BGR:``` Converts an image from __HSV__ to __BGR__.\n",
    "  - ```cv2.COLOR_BGR2RGB:``` Converts an image from __BGR__ to __RGB__.\n",
    "* ```dst:``` Output Variable \n",
    "* ```dstCn:``` This is the number of channels in the output image. The default value is 0, which matches the number of channels in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46d7f38-dbfb-4160-b542-130847cbed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv2.imread('imgs/fruits.png')\n",
    "# BGR to grayscale\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original Image', img_bgr)\n",
    "cv2.imshow('Grayscale Image', img_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb71a6c-c7b1-4130-878e-7f03d869dfc8",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.5.4.Hue Saturation Lightness (HSL) color space <a id='HSL'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6da73-daa4-40ac-be79-950a4521e2c4",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "The color space is similar to HSV color space, but there’s a slight difference in how they calculate brightness.\n",
    "* ```Hue:``` This is similar to the description in the HSV channel.\n",
    "* ```Saturation:``` This is also similar to the description in the HSV channel.\n",
    "* ```Lightness:``` Lightness is the measure of how bright or dark the color is, with $0%$ lightness being black and $100%$ lightness being white. This is useful for brightening or darkening images as well as for adding creative touches to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfafa20-1944-4431-bd11-859836104415",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.5.5.LAB color space <a id='LAB'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815b86a-c552-48eb-83ab-62be87a61254",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "The LAB color space was designed to resemble the human vision system closely.The LAB color space consists of three dimensions:\n",
    "* ```L channel (Lightness):``` The L channel represents the lightness dimension.The values are in the range of 0 to 100 where 0 is the lowest brightness(black) and 100 is the brightest (white).\n",
    "  - ```a channel (Green - Red):``` This defines pure green color on one side and pure red color on the opposite side. The values for this dimension range from __$-128$__ to __$+127$__ and define the color between green to red channels.\n",
    "  - ```b channel (Blue - Yellow):``` This defines pure blue color on one side and pure red color on the opposite side. The values for this dimension range from __$-128$__ to __$+127$__ and define the color between blue to yellow channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dad181-4c4a-47e4-a07f-4fa366ce8385",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.5.6.YCbCr color space <a id='YCbCr'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1292d9a-d7bd-4dbe-b8b4-0e23be036187",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "The YCbCr color space is a color encoding system that represents colors as a combination of brightness __(luma)__ and two color-difference signals __(chroma)__. \n",
    "YCbCr color space is similar to the RGB color space, but it uses luminance (Y), blue-difference (Cb), and red-difference (Cr) components instead of red, green, and blue.\n",
    "* ```Y channel:``` This channel represents the brightness of the color and is sometimes referred to as the luminance channel.\n",
    "* ```Cb and Cr channels:``` These channels represent the color information of the image. The Cb channel represents the blue-difference, and the Cr channel represents the red-difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f4a79-a60b-45b3-a20b-787cef8e708c",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.5.7.Grayscale <a id='Grayscale'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65997660-0f72-4bae-a07d-e13f6d32c5de",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Images in grayscale are represented in a single channel only and contain values from 0 to 255. This value indicated the amount of light on the pixel. In most standard algorithms for converting RGB to grayscale, the red, green, and blue channels are not given equal weights. One common method is to use the formula:\n",
    "\n",
    "$$ Grayscale = 0.2989 * Red + 0.5870 * Green + 0.1140 * Blue $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
